{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens/Projetos/paper - llm embeddings to classification - marcacini - matheus\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Configura o Pandas para exibir todas as colunas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def load_results_to_dataframe(base_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load results from JSON files into a pandas DataFrame.\n",
    "\n",
    "    This function traverses the directory structure under the given base path, \n",
    "    finds the results.json files, calculates the average for list values, \n",
    "    and compiles the results into a DataFrame with additional metadata \n",
    "    such as dataset name, model type, and model name.\n",
    "\n",
    "    Parameters:\n",
    "    - base_path (str): The base directory path containing the results.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame containing the consolidated results.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Traverse the directory structure\n",
    "    for dataset_name in os.listdir(base_path):\n",
    "        dataset_path = os.path.join(base_path, dataset_name)\n",
    "        if os.path.isdir(dataset_path):\n",
    "            for model_type in os.listdir(dataset_path):\n",
    "                model_type_path = os.path.join(dataset_path, model_type)\n",
    "                \n",
    "                if os.path.isdir(model_type_path):\n",
    "                    for model_name in os.listdir(model_type_path):\n",
    "                        model_name_path = os.path.join(model_type_path, model_name)\n",
    "                        json_file_path = os.path.join(model_name_path, 'results.json')\n",
    "                        \n",
    "                        embeddings_path = os.path.join(model_name_path, 'embeddings.npy')\n",
    "                        if(os.path.exists(embeddings_path)):\n",
    "                            embeddings_size = os.path.getsize(embeddings_path)\n",
    "                        else:\n",
    "                            embeddings_size = None\n",
    "                        # Check if results.json file exists\n",
    "                        if os.path.isfile(json_file_path):\n",
    "                            with open(json_file_path, 'r') as json_file:\n",
    "                                result_data = json.load(json_file)\n",
    "                                \n",
    "                                # Calculate the mean for each list\n",
    "                                for key in result_data.keys():\n",
    "                                    if isinstance(result_data[key], list):\n",
    "                                        result_data[key] = sum(result_data[key]) / len(result_data[key])\n",
    "                                \n",
    "                                # Add metadata to the result data\n",
    "                                result_data['dataset_name'] = dataset_name\n",
    "                                result_data['model_type'] = model_type\n",
    "                                result_data['model_name'] = model_name\n",
    "                                result_data['embeddings_size'] = embeddings_size\n",
    "                                results.append(result_data)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Specify the order of the columns, putting 'dataset_name', 'model_type', and 'model_name' first\n",
    "    columns_first = ['dataset_name', 'model_type', 'model_name']\n",
    "    column_order = columns_first + [col for col in results_df.columns if col not in columns_first]\n",
    "    results_df = results_df[column_order]\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame of Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>score_time</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_f1_score</th>\n",
       "      <th>train_f1_score</th>\n",
       "      <th>embedding_generation_time</th>\n",
       "      <th>embeddings_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-MiniLM-L6-v2</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.017229</td>\n",
       "      <td>0.913116</td>\n",
       "      <td>0.929647</td>\n",
       "      <td>0.910773</td>\n",
       "      <td>0.930965</td>\n",
       "      <td>0.896079</td>\n",
       "      <td>0.915246</td>\n",
       "      <td>0.898112</td>\n",
       "      <td>0.921168</td>\n",
       "      <td>2.715869</td>\n",
       "      <td>513152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-MiniLM-L12-v2</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>0.910176</td>\n",
       "      <td>0.929641</td>\n",
       "      <td>0.915087</td>\n",
       "      <td>0.931200</td>\n",
       "      <td>0.896763</td>\n",
       "      <td>0.917989</td>\n",
       "      <td>0.901097</td>\n",
       "      <td>0.923040</td>\n",
       "      <td>2.643802</td>\n",
       "      <td>513152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-mpnet-base-v2</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>0.019538</td>\n",
       "      <td>0.901085</td>\n",
       "      <td>0.913170</td>\n",
       "      <td>0.904716</td>\n",
       "      <td>0.914158</td>\n",
       "      <td>0.884785</td>\n",
       "      <td>0.896956</td>\n",
       "      <td>0.888635</td>\n",
       "      <td>0.902096</td>\n",
       "      <td>3.382855</td>\n",
       "      <td>1026176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dmoz-Computers.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-MiniLM-L6-v2</td>\n",
       "      <td>0.008594</td>\n",
       "      <td>0.376299</td>\n",
       "      <td>0.721474</td>\n",
       "      <td>0.773211</td>\n",
       "      <td>0.717329</td>\n",
       "      <td>0.775273</td>\n",
       "      <td>0.715111</td>\n",
       "      <td>0.767667</td>\n",
       "      <td>0.705807</td>\n",
       "      <td>0.760638</td>\n",
       "      <td>6.331421</td>\n",
       "      <td>14592128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dmoz-Computers.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-MiniLM-L12-v2</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.428401</td>\n",
       "      <td>0.719474</td>\n",
       "      <td>0.771974</td>\n",
       "      <td>0.714759</td>\n",
       "      <td>0.774625</td>\n",
       "      <td>0.711611</td>\n",
       "      <td>0.765375</td>\n",
       "      <td>0.699790</td>\n",
       "      <td>0.757391</td>\n",
       "      <td>3.932108</td>\n",
       "      <td>14592128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>webkb-parsed.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-unsup-si...</td>\n",
       "      <td>0.044932</td>\n",
       "      <td>0.394923</td>\n",
       "      <td>0.737021</td>\n",
       "      <td>0.782058</td>\n",
       "      <td>0.603201</td>\n",
       "      <td>0.734023</td>\n",
       "      <td>0.653469</td>\n",
       "      <td>0.698658</td>\n",
       "      <td>0.599817</td>\n",
       "      <td>0.652680</td>\n",
       "      <td>152.077099</td>\n",
       "      <td>67846272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>webkb-parsed.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...</td>\n",
       "      <td>0.175954</td>\n",
       "      <td>0.741229</td>\n",
       "      <td>0.724947</td>\n",
       "      <td>0.778858</td>\n",
       "      <td>0.587702</td>\n",
       "      <td>0.735252</td>\n",
       "      <td>0.658053</td>\n",
       "      <td>0.707258</td>\n",
       "      <td>0.586608</td>\n",
       "      <td>0.652269</td>\n",
       "      <td>479.219994</td>\n",
       "      <td>135692416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>webkb-parsed.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...</td>\n",
       "      <td>0.097515</td>\n",
       "      <td>0.716436</td>\n",
       "      <td>0.698620</td>\n",
       "      <td>0.760565</td>\n",
       "      <td>0.591510</td>\n",
       "      <td>0.729517</td>\n",
       "      <td>0.623665</td>\n",
       "      <td>0.681909</td>\n",
       "      <td>0.554618</td>\n",
       "      <td>0.628967</td>\n",
       "      <td>518.274609</td>\n",
       "      <td>135692416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>webkb-parsed.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...</td>\n",
       "      <td>0.108003</td>\n",
       "      <td>0.595790</td>\n",
       "      <td>0.738227</td>\n",
       "      <td>0.788880</td>\n",
       "      <td>0.611827</td>\n",
       "      <td>0.744922</td>\n",
       "      <td>0.660979</td>\n",
       "      <td>0.711210</td>\n",
       "      <td>0.598923</td>\n",
       "      <td>0.667003</td>\n",
       "      <td>518.035170</td>\n",
       "      <td>135692416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>webkb-parsed.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...</td>\n",
       "      <td>0.083144</td>\n",
       "      <td>0.699962</td>\n",
       "      <td>0.687998</td>\n",
       "      <td>0.755886</td>\n",
       "      <td>0.622040</td>\n",
       "      <td>0.732481</td>\n",
       "      <td>0.614141</td>\n",
       "      <td>0.671028</td>\n",
       "      <td>0.550611</td>\n",
       "      <td>0.625094</td>\n",
       "      <td>478.364359</td>\n",
       "      <td>135692416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset_name model_type  \\\n",
       "0     SyskillWebert.csv       bert   \n",
       "1     SyskillWebert.csv       bert   \n",
       "2     SyskillWebert.csv       bert   \n",
       "3    Dmoz-Computers.csv       bert   \n",
       "4    Dmoz-Computers.csv       bert   \n",
       "..                  ...        ...   \n",
       "97     webkb-parsed.csv    llm2vec   \n",
       "98     webkb-parsed.csv    llm2vec   \n",
       "99     webkb-parsed.csv    llm2vec   \n",
       "100    webkb-parsed.csv    llm2vec   \n",
       "101    webkb-parsed.csv    llm2vec   \n",
       "\n",
       "                                            model_name  fit_time  score_time  \\\n",
       "0               sentence-transformers_all-MiniLM-L6-v2  0.000506    0.017229   \n",
       "1              sentence-transformers_all-MiniLM-L12-v2  0.000531    0.016526   \n",
       "2              sentence-transformers_all-mpnet-base-v2  0.000780    0.019538   \n",
       "3               sentence-transformers_all-MiniLM-L6-v2  0.008594    0.376299   \n",
       "4              sentence-transformers_all-MiniLM-L12-v2  0.009866    0.428401   \n",
       "..                                                 ...       ...         ...   \n",
       "97   McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-unsup-si...  0.044932    0.394923   \n",
       "98   McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...  0.175954    0.741229   \n",
       "99   McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...  0.097515    0.716436   \n",
       "100  McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...  0.108003    0.595790   \n",
       "101  McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...  0.083144    0.699962   \n",
       "\n",
       "     test_accuracy  train_accuracy  test_precision  train_precision  \\\n",
       "0         0.913116        0.929647        0.910773         0.930965   \n",
       "1         0.910176        0.929641        0.915087         0.931200   \n",
       "2         0.901085        0.913170        0.904716         0.914158   \n",
       "3         0.721474        0.773211        0.717329         0.775273   \n",
       "4         0.719474        0.771974        0.714759         0.774625   \n",
       "..             ...             ...             ...              ...   \n",
       "97        0.737021        0.782058        0.603201         0.734023   \n",
       "98        0.724947        0.778858        0.587702         0.735252   \n",
       "99        0.698620        0.760565        0.591510         0.729517   \n",
       "100       0.738227        0.788880        0.611827         0.744922   \n",
       "101       0.687998        0.755886        0.622040         0.732481   \n",
       "\n",
       "     test_recall  train_recall  test_f1_score  train_f1_score  \\\n",
       "0       0.896079      0.915246       0.898112        0.921168   \n",
       "1       0.896763      0.917989       0.901097        0.923040   \n",
       "2       0.884785      0.896956       0.888635        0.902096   \n",
       "3       0.715111      0.767667       0.705807        0.760638   \n",
       "4       0.711611      0.765375       0.699790        0.757391   \n",
       "..           ...           ...            ...             ...   \n",
       "97      0.653469      0.698658       0.599817        0.652680   \n",
       "98      0.658053      0.707258       0.586608        0.652269   \n",
       "99      0.623665      0.681909       0.554618        0.628967   \n",
       "100     0.660979      0.711210       0.598923        0.667003   \n",
       "101     0.614141      0.671028       0.550611        0.625094   \n",
       "\n",
       "     embedding_generation_time  embeddings_size  \n",
       "0                     2.715869           513152  \n",
       "1                     2.643802           513152  \n",
       "2                     3.382855          1026176  \n",
       "3                     6.331421         14592128  \n",
       "4                     3.932108         14592128  \n",
       "..                         ...              ...  \n",
       "97                  152.077099         67846272  \n",
       "98                  479.219994        135692416  \n",
       "99                  518.274609        135692416  \n",
       "100                 518.035170        135692416  \n",
       "101                 478.364359        135692416  \n",
       "\n",
       "[102 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usage\n",
    "base_path = 'results' \n",
    "results_df = load_results_to_dataframe(base_path)\n",
    "\n",
    "print(\"DataFrame of Results:\")\n",
    "display(results_df)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "results_df.to_csv(f'{base_path}/result_resume.csv', index=False)  # Include index=False to avoid saving the index as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = results_df['dataset_name'].unique()\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    display(results_df[results_df['dataset_name'] == dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dataset_name', 'model_type', 'model_name', 'fit_time', 'score_time',\n",
       "       'test_accuracy', 'train_accuracy', 'test_precision', 'train_precision',\n",
       "       'test_recall', 'train_recall', 'test_f1_score', 'train_f1_score',\n",
       "       'embedding_generation_time', 'embeddings_size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF gerado: consolidated_report.pdf\n"
     ]
    }
   ],
   "source": [
    "import pdfkit\n",
    "\n",
    "# Lista de datasets únicos\n",
    "datasets = results_df['dataset_name'].unique()\n",
    "\n",
    "columns = ['model_type', 'model_name', 'fit_time', 'score_time', 'test_accuracy',  'test_precision', 'test_recall', 'test_f1_score','embedding_generation_time', 'embeddings_size']\n",
    "\n",
    "# HTML para o PDF consolidado\n",
    "html_content = \"\"\n",
    "\n",
    "for dataset in datasets:\n",
    "    # Filtra o DataFrame por dataset\n",
    "    filtered_df = results_df[results_df['dataset_name'] == dataset]\n",
    "    filtered_df = filtered_df[columns]\n",
    "    filtered_df = filtered_df.sort_values(by = \"test_f1_score\", ascending = False)\n",
    "    \n",
    "    # Adiciona título e conteúdo do DataFrame ao HTML\n",
    "    html_content += f\"<h2>Dataset: {dataset}</h2>\"\n",
    "    html_content += filtered_df.to_html(index=False)\n",
    "    html_content += \"<br><br>\"  # Adiciona um espaço entre os datasets\n",
    "\n",
    "# Gera o PDF consolidado\n",
    "pdf_filename = \"consolidated_report.pdf\"\n",
    "pdfkit.from_string(html_content, pdf_filename)\n",
    "print(f\"PDF gerado: {pdf_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
