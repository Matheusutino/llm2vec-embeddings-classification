{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.core.utils import read_json\n",
    "\n",
    "# Configura o Pandas para exibir todas as colunas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def load_results_to_dataframe(base_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load results from JSON files into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Traverse the directory structure\n",
    "    for dataset_name in os.listdir(base_path):\n",
    "        dataset_path = os.path.join(base_path, dataset_name)\n",
    "        if os.path.isdir(dataset_path):\n",
    "            for model_type in os.listdir(dataset_path):\n",
    "                model_type_path = os.path.join(dataset_path, model_type)\n",
    "                \n",
    "                if os.path.isdir(model_type_path):\n",
    "                    for model_name in os.listdir(model_type_path):\n",
    "                        model_name_path = os.path.join(model_type_path, model_name)\n",
    "                        \n",
    "                        # Define paths based on whether prompt_name is needed\n",
    "                        if model_type != \"bert\":\n",
    "                            subdirs = [os.path.join(model_name_path, prompt) for prompt in os.listdir(model_name_path)]\n",
    "                        else:\n",
    "                            subdirs = [model_name_path]\n",
    "                        \n",
    "                        # Process results.json files from determined paths\n",
    "                        for subdir in subdirs:\n",
    "                            for classifier in os.listdir(subdir):\n",
    "                                classifier_path = os.path.join(subdir, classifier)\n",
    "                                \n",
    "                                # Check for the results.json in the classifier path\n",
    "                                json_file_path = os.path.join(classifier_path, 'results.json')\n",
    "                                \n",
    "                                if os.path.isfile(json_file_path):\n",
    "                                    result_data = read_json(json_file_path)\n",
    "\n",
    "                                    keys_to_extract = [\"split0_test_f1_score\", \"split1_test_f1_score\", \"split2_test_f1_score\", \"split3_test_f1_score\", \"split4_test_f1_score\", 'embedding_generation_time', 'embedding_generation_size']\n",
    "    \n",
    "                                    # Extrai apenas as chaves especificadas\n",
    "                                    result_data= {key: result_data.get(key) for key in keys_to_extract}\n",
    "                                    \n",
    "                                    # Add metadata to the result data\n",
    "                                    result_data['dataset_name'] = dataset_name\n",
    "                                    result_data['model_type'] = model_type\n",
    "                                    result_data['model_name'] = model_name\n",
    "                                    result_data['classifier'] = classifier\n",
    "                                    \n",
    "                                    # Add prompt_name if applicable\n",
    "                                    if model_type != \"bert\":\n",
    "                                        result_data['prompt_name'] = os.path.basename(subdir)\n",
    "                                    else:\n",
    "                                        result_data['prompt_name'] = None\n",
    "                                    \n",
    "                                    results.append(result_data)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Specify the order of the columns\n",
    "    columns_first = ['dataset_name', 'model_type', 'model_name', 'classifier']\n",
    "    if 'prompt_name' in results_df.columns:\n",
    "        columns_first.append('prompt_name')\n",
    "    column_order = columns_first + [col for col in results_df.columns if col not in columns_first]\n",
    "    results_df = results_df[column_order]\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>split0_test_f1_score</th>\n",
       "      <th>split1_test_f1_score</th>\n",
       "      <th>split2_test_f1_score</th>\n",
       "      <th>split3_test_f1_score</th>\n",
       "      <th>split4_test_f1_score</th>\n",
       "      <th>embedding_generation_time</th>\n",
       "      <th>embedding_generation_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dmoz-Computers.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-distilroberta-v1</td>\n",
       "      <td>knn</td>\n",
       "      <td>None</td>\n",
       "      <td>0.708965</td>\n",
       "      <td>0.698970</td>\n",
       "      <td>0.707780</td>\n",
       "      <td>0.716755</td>\n",
       "      <td>0.708086</td>\n",
       "      <td>4.272044</td>\n",
       "      <td>29184128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dmoz-Computers.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-MiniLM-L6-v2</td>\n",
       "      <td>knn</td>\n",
       "      <td>None</td>\n",
       "      <td>0.711310</td>\n",
       "      <td>0.708279</td>\n",
       "      <td>0.706688</td>\n",
       "      <td>0.719293</td>\n",
       "      <td>0.729984</td>\n",
       "      <td>3.669558</td>\n",
       "      <td>14592128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dmoz-Computers.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-MiniLM-L12-v2</td>\n",
       "      <td>knn</td>\n",
       "      <td>None</td>\n",
       "      <td>0.703686</td>\n",
       "      <td>0.708847</td>\n",
       "      <td>0.716030</td>\n",
       "      <td>0.722475</td>\n",
       "      <td>0.711265</td>\n",
       "      <td>4.991892</td>\n",
       "      <td>14592128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dmoz-Computers.csv</td>\n",
       "      <td>bert</td>\n",
       "      <td>sentence-transformers_all-mpnet-base-v2</td>\n",
       "      <td>knn</td>\n",
       "      <td>None</td>\n",
       "      <td>0.725192</td>\n",
       "      <td>0.721513</td>\n",
       "      <td>0.710816</td>\n",
       "      <td>0.731876</td>\n",
       "      <td>0.733004</td>\n",
       "      <td>9.260681</td>\n",
       "      <td>29184128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dmoz-Computers.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_summary_prompt</td>\n",
       "      <td>0.775330</td>\n",
       "      <td>0.752068</td>\n",
       "      <td>0.771297</td>\n",
       "      <td>0.771387</td>\n",
       "      <td>0.775164</td>\n",
       "      <td>41.051134</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>NSF.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>0.883162</td>\n",
       "      <td>0.874623</td>\n",
       "      <td>0.868259</td>\n",
       "      <td>0.873625</td>\n",
       "      <td>0.874772</td>\n",
       "      <td>239.332735</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>NSF.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...</td>\n",
       "      <td>knn</td>\n",
       "      <td>base_prompt</td>\n",
       "      <td>0.880013</td>\n",
       "      <td>0.878815</td>\n",
       "      <td>0.863143</td>\n",
       "      <td>0.880184</td>\n",
       "      <td>0.879590</td>\n",
       "      <td>63.920336</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>NSF.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_summary_prompt</td>\n",
       "      <td>0.889105</td>\n",
       "      <td>0.878020</td>\n",
       "      <td>0.885468</td>\n",
       "      <td>0.889903</td>\n",
       "      <td>0.888813</td>\n",
       "      <td>137.549927</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>NSF.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>0.878154</td>\n",
       "      <td>0.867611</td>\n",
       "      <td>0.866053</td>\n",
       "      <td>0.877906</td>\n",
       "      <td>0.878015</td>\n",
       "      <td>221.728992</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>NSF.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...</td>\n",
       "      <td>knn</td>\n",
       "      <td>base_prompt</td>\n",
       "      <td>0.900830</td>\n",
       "      <td>0.888362</td>\n",
       "      <td>0.889693</td>\n",
       "      <td>0.898957</td>\n",
       "      <td>0.901017</td>\n",
       "      <td>55.149740</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dataset_name model_type  \\\n",
       "0    Dmoz-Computers.csv       bert   \n",
       "1    Dmoz-Computers.csv       bert   \n",
       "2    Dmoz-Computers.csv       bert   \n",
       "3    Dmoz-Computers.csv       bert   \n",
       "4    Dmoz-Computers.csv    llm2vec   \n",
       "..                  ...        ...   \n",
       "105             NSF.csv    llm2vec   \n",
       "106             NSF.csv    llm2vec   \n",
       "107             NSF.csv    llm2vec   \n",
       "108             NSF.csv    llm2vec   \n",
       "109             NSF.csv    llm2vec   \n",
       "\n",
       "                                            model_name classifier  \\\n",
       "0           sentence-transformers_all-distilroberta-v1        knn   \n",
       "1               sentence-transformers_all-MiniLM-L6-v2        knn   \n",
       "2              sentence-transformers_all-MiniLM-L12-v2        knn   \n",
       "3              sentence-transformers_all-mpnet-base-v2        knn   \n",
       "4     McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised        knn   \n",
       "..                                                 ...        ...   \n",
       "105  McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...        knn   \n",
       "106  McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...        knn   \n",
       "107  McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...        knn   \n",
       "108  McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...        knn   \n",
       "109  McGill-NLP_LLM2Vec-Meta-Llama-3-8B-Instruct-mn...        knn   \n",
       "\n",
       "                           prompt_name  split0_test_f1_score  \\\n",
       "0                                 None              0.708965   \n",
       "1                                 None              0.711310   \n",
       "2                                 None              0.703686   \n",
       "3                                 None              0.725192   \n",
       "4           instruction_summary_prompt              0.775330   \n",
       "..                                 ...                   ...   \n",
       "105  instruction_classification_prompt              0.883162   \n",
       "106                        base_prompt              0.880013   \n",
       "107         instruction_summary_prompt              0.889105   \n",
       "108  instruction_classification_prompt              0.878154   \n",
       "109                        base_prompt              0.900830   \n",
       "\n",
       "     split1_test_f1_score  split2_test_f1_score  split3_test_f1_score  \\\n",
       "0                0.698970              0.707780              0.716755   \n",
       "1                0.708279              0.706688              0.719293   \n",
       "2                0.708847              0.716030              0.722475   \n",
       "3                0.721513              0.710816              0.731876   \n",
       "4                0.752068              0.771297              0.771387   \n",
       "..                    ...                   ...                   ...   \n",
       "105              0.874623              0.868259              0.873625   \n",
       "106              0.878815              0.863143              0.880184   \n",
       "107              0.878020              0.885468              0.889903   \n",
       "108              0.867611              0.866053              0.877906   \n",
       "109              0.888362              0.889693              0.898957   \n",
       "\n",
       "     split4_test_f1_score  embedding_generation_time  \\\n",
       "0                0.708086                   4.272044   \n",
       "1                0.729984                   3.669558   \n",
       "2                0.711265                   4.991892   \n",
       "3                0.733004                   9.260681   \n",
       "4                0.775164                  41.051134   \n",
       "..                    ...                        ...   \n",
       "105              0.874772                 239.332735   \n",
       "106              0.879590                  63.920336   \n",
       "107              0.888813                 137.549927   \n",
       "108              0.878015                 221.728992   \n",
       "109              0.901017                  55.149740   \n",
       "\n",
       "     embedding_generation_size  \n",
       "0                     29184128  \n",
       "1                     14592128  \n",
       "2                     14592128  \n",
       "3                     29184128  \n",
       "4                          128  \n",
       "..                         ...  \n",
       "105                        128  \n",
       "106                        128  \n",
       "107                        128  \n",
       "108                        128  \n",
       "109                        128  \n",
       "\n",
       "[110 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'results' \n",
    "\n",
    "df = load_results_to_dataframe(base_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_prompt</td>\n",
       "      <td>[0.7723636763722447, 0.763658005103482, 0.7634...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>[0.753274119106956, 0.7408529426699233, 0.7467...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instruction_summary_prompt</td>\n",
       "      <td>[0.7753301888686077, 0.7520678321654, 0.771296...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         prompt_name  \\\n",
       "0                        base_prompt   \n",
       "1  instruction_classification_prompt   \n",
       "2         instruction_summary_prompt   \n",
       "\n",
       "                                                   0  \n",
       "0  [0.7723636763722447, 0.763658005103482, 0.7634...  \n",
       "1  [0.753274119106956, 0.7408529426699233, 0.7467...  \n",
       "2  [0.7753301888686077, 0.7520678321654, 0.771296...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemplo de DataFrame (substitua pelo seu df real)\n",
    "# df = pd.DataFrame({...})\n",
    "\n",
    "# Defina os splits que você quer combinar\n",
    "splits = ['split0_test_f1_score', \n",
    "          'split1_test_f1_score', \n",
    "          'split2_test_f1_score', \n",
    "          'split3_test_f1_score', \n",
    "          'split4_test_f1_score']\n",
    "\n",
    "# Agrupar pelo 'prompt_name' e combinar os splits em uma lista para cada 'prompt_name'\n",
    "df_combined = df.groupby('prompt_name')[splits].apply(lambda x: x.values.flatten().tolist()).reset_index()\n",
    "\n",
    "# Exibir o resultado\n",
    "df_combined  # A coluna 0 contém a lista dos splits combinados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variância para base_prompt: 0.004436530205440216\n",
      "Variância para instruction_summary_prompt: 0.004257131661144218\n",
      "Variância para instruction_classification_prompt: 0.004086945446258278\n",
      "\n",
      "Resultado do ANOVA:\n",
      "Statistic: 0.3848971214194376 p-value: 0.6807459620446685\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "base_prompt = df_combined[df_combined['prompt_name'] == \"base_prompt\"][0].tolist()[0]\n",
    "instruction_summary_prompt = df_combined[df_combined['prompt_name'] == \"instruction_summary_prompt\"][0].tolist()[0]\n",
    "instruction_classification_prompt = df_combined[df_combined['prompt_name'] == \"instruction_classification_prompt\"][0].tolist()[0]\n",
    "\n",
    "# Calcule as variâncias para cada grupo\n",
    "var_base = np.var(base_prompt)\n",
    "var_summary = np.var(instruction_summary_prompt)\n",
    "var_classification = np.var(instruction_classification_prompt)\n",
    "\n",
    "print(\"Variância para base_prompt:\", var_base)\n",
    "print(\"Variância para instruction_summary_prompt:\", var_summary)\n",
    "print(\"Variância para instruction_classification_prompt:\", var_classification)\n",
    "\n",
    "# Execute o ANOVA clássico para comparar as médias dos grupos\n",
    "anova_result = f_oneway(base_prompt, instruction_summary_prompt, instruction_classification_prompt)\n",
    "\n",
    "print(\"\\nResultado do ANOVA:\")\n",
    "print(\"Statistic:\", anova_result.statistic, \"p-value:\", anova_result.pvalue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste Mann-Whitney: estatística=1793.0, p-valor=4.621730739866808e-12\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind, mannwhitneyu\n",
    "\n",
    "# Separando os tempos por modelo\n",
    "time_llm2vec = df[df['model_type'] == 'llm2vec']['embedding_generation_time']\n",
    "time_bert = df[df['model_type'] == 'bert']['embedding_generation_time']\n",
    "\n",
    "# Teste de Mann-Whitney\n",
    "mw_stat, mw_pval = mannwhitneyu(time_llm2vec, time_bert)\n",
    "print(f\"Teste Mann-Whitney: estatística={mw_stat}, p-valor={mw_pval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_test_f1_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_test_f1_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Separando os tempos por modelo\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m tempos_llm2vec \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mllm2vec\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean_test_f1_score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m tempos_bert \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbert\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_f1_score\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Teste de Mann-Whitney\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_test_f1_score'"
     ]
    }
   ],
   "source": [
    "# Separando os tempos por modelo\n",
    "tempos_llm2vec = df[df['model_type'] == 'llm2vec']['mean_test_f1_score']\n",
    "tempos_bert = df[df['model_type'] == 'bert']['mean_test_f1_score']\n",
    "\n",
    "# Teste de Mann-Whitney\n",
    "mw_stat, mw_pval = mannwhitneyu(tempos_llm2vec, tempos_bert)\n",
    "print(f\"Teste Mann-Whitney: estatística={mw_stat}, p-valor={mw_pval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste de Shapiro-Wilk para base_prompt:\n",
      "Statistic: 0.9736904972818591 p-value: 0.6442262521848311\n",
      "\n",
      "Teste de Shapiro-Wilk para instruction_summary_prompt:\n",
      "Statistic: 0.9560738779996244 p-value: 0.24506938060597977\n",
      "\n",
      "Teste de Shapiro-Wilk para instruction_classification_prompt:\n",
      "Statistic: 0.9602047894188402 p-value: 0.3135277844008573\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Supondo que 'df' seja o seu DataFrame\n",
    "# Separe os dados de 'mean_test_f1_score' para cada prompt\n",
    "base_prompt = df[df['prompt_name'] == 'base_prompt']['mean_test_f1_score']\n",
    "instruction_summary_prompt = df[df['prompt_name'] == 'instruction_summary_prompt']['mean_test_f1_score']\n",
    "instruction_classification_prompt = df[df['prompt_name'] == 'instruction_classification_prompt']['mean_test_f1_score']\n",
    "\n",
    "# Realize o Teste de Shapiro-Wilk para cada grupo\n",
    "shapiro_base = shapiro(base_prompt)\n",
    "shapiro_summary = shapiro(instruction_summary_prompt)\n",
    "shapiro_classification = shapiro(instruction_classification_prompt)\n",
    "\n",
    "# Exibe os resultados do teste\n",
    "print(\"Teste de Shapiro-Wilk para base_prompt:\")\n",
    "print(\"Statistic:\", shapiro_base.statistic, \"p-value:\", shapiro_base.pvalue)\n",
    "\n",
    "print(\"\\nTeste de Shapiro-Wilk para instruction_summary_prompt:\")\n",
    "print(\"Statistic:\", shapiro_summary.statistic, \"p-value:\", shapiro_summary.pvalue)\n",
    "\n",
    "print(\"\\nTeste de Shapiro-Wilk para instruction_classification_prompt:\")\n",
    "print(\"Statistic:\", shapiro_classification.statistic, \"p-value:\", shapiro_classification.pvalue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variância para base_prompt: 0.004456345961475927\n",
      "Variância para instruction_summary_prompt: 0.004256975670279224\n",
      "Variância para instruction_classification_prompt: 0.004104426742356053\n",
      "\n",
      "Resultado do ANOVA:\n",
      "Statistic: 0.07727150998046275 p-value: 0.9257019538195259\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Calcule as variâncias para cada grupo\n",
    "var_base = base_prompt.var()\n",
    "var_summary = instruction_summary_prompt.var()\n",
    "var_classification = instruction_classification_prompt.var()\n",
    "\n",
    "print(\"Variância para base_prompt:\", var_base)\n",
    "print(\"Variância para instruction_summary_prompt:\", var_summary)\n",
    "print(\"Variância para instruction_classification_prompt:\", var_classification)\n",
    "\n",
    "# Execute o ANOVA clássico para comparar as médias dos grupos\n",
    "anova_result = f_oneway(base_prompt, instruction_summary_prompt, instruction_classification_prompt)\n",
    "\n",
    "print(\"\\nResultado do ANOVA:\")\n",
    "print(\"Statistic:\", anova_result.statistic, \"p-value:\", anova_result.pvalue)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
