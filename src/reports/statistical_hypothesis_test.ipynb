{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/matheus/Desktop/Itens/Projetos/llm2vec-embeddings-classification\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.core.utils import read_json\n",
    "\n",
    "# Configura o Pandas para exibir todas as colunas\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "def load_results_to_dataframe(base_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load results from JSON files into a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    # Traverse the directory structure\n",
    "    for dataset_name in os.listdir(base_path):\n",
    "        dataset_path = os.path.join(base_path, dataset_name)\n",
    "        if os.path.isdir(dataset_path):\n",
    "            for model_type in os.listdir(dataset_path):\n",
    "                model_type_path = os.path.join(dataset_path, model_type)\n",
    "                \n",
    "                if os.path.isdir(model_type_path):\n",
    "                    for model_name in os.listdir(model_type_path):\n",
    "                        if model_name == \"phi3.5:3.8b\":\n",
    "                            continue\n",
    "                        model_name_path = os.path.join(model_type_path, model_name)\n",
    "                        \n",
    "                        # Define paths based on whether prompt_name is needed\n",
    "                        if model_type != \"bert\":\n",
    "                            subdirs = [os.path.join(model_name_path, prompt) for prompt in os.listdir(model_name_path)]\n",
    "                        else:\n",
    "                            subdirs = [model_name_path]\n",
    "                        \n",
    "                        # Process results.json files from determined paths\n",
    "                        for subdir in subdirs:\n",
    "                            for classifier in os.listdir(subdir):\n",
    "\n",
    "                                classifier_path = os.path.join(subdir, classifier)\n",
    "                                \n",
    "                                # Check for the results.json in the classifier path\n",
    "                                json_file_path = os.path.join(classifier_path, 'results.json')\n",
    "                                \n",
    "                                if os.path.isfile(json_file_path):\n",
    "                                    result_data = read_json(json_file_path)\n",
    "\n",
    "                                    keys_to_extract = [\"split0_test_f1_score\", \"split1_test_f1_score\", \"split2_test_f1_score\", \"split3_test_f1_score\", \"split4_test_f1_score\", \"mean_test_f1_score\", \"embedding_generation_time\", \"embedding_generation_size\"]\n",
    "    \n",
    "                                    # Extrai apenas as chaves especificadas\n",
    "                                    result_data= {key: result_data.get(key) for key in keys_to_extract}\n",
    "                                    \n",
    "                                    # Add metadata to the result data\n",
    "                                    result_data['dataset_name'] = dataset_name\n",
    "                                    result_data['model_type'] = model_type\n",
    "                                    result_data['model_name'] = model_name\n",
    "                                    result_data['classifier'] = classifier\n",
    "                                    \n",
    "                                    # Add prompt_name if applicable\n",
    "                                    if model_type != \"bert\":\n",
    "                                        result_data['prompt_name'] = os.path.basename(subdir)\n",
    "                                    else:\n",
    "                                        result_data['prompt_name'] = None\n",
    "                                    \n",
    "                                    results.append(result_data)\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Specify the order of the columns\n",
    "    columns_first = ['dataset_name', 'model_type', 'model_name', 'classifier']\n",
    "    if 'prompt_name' in results_df.columns:\n",
    "        columns_first.append('prompt_name')\n",
    "    column_order = columns_first + [col for col in results_df.columns if col not in columns_first]\n",
    "    results_df = results_df[column_order]\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>split0_test_f1_score</th>\n",
       "      <th>split1_test_f1_score</th>\n",
       "      <th>split2_test_f1_score</th>\n",
       "      <th>split3_test_f1_score</th>\n",
       "      <th>split4_test_f1_score</th>\n",
       "      <th>mean_test_f1_score</th>\n",
       "      <th>embedding_generation_time</th>\n",
       "      <th>embedding_generation_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dmoz-Science.csv</td>\n",
       "      <td>ollama</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_summary_prompt</td>\n",
       "      <td>0.593222</td>\n",
       "      <td>0.592466</td>\n",
       "      <td>0.602268</td>\n",
       "      <td>0.561719</td>\n",
       "      <td>0.578065</td>\n",
       "      <td>0.585548</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dmoz-Science.csv</td>\n",
       "      <td>ollama</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>0.629638</td>\n",
       "      <td>0.649192</td>\n",
       "      <td>0.665732</td>\n",
       "      <td>0.634082</td>\n",
       "      <td>0.634035</td>\n",
       "      <td>0.642536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dmoz-Science.csv</td>\n",
       "      <td>ollama</td>\n",
       "      <td>mistral:7b</td>\n",
       "      <td>knn</td>\n",
       "      <td>base_prompt</td>\n",
       "      <td>0.537706</td>\n",
       "      <td>0.551799</td>\n",
       "      <td>0.563238</td>\n",
       "      <td>0.549503</td>\n",
       "      <td>0.546192</td>\n",
       "      <td>0.549688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dmoz-Science.csv</td>\n",
       "      <td>ollama</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_summary_prompt</td>\n",
       "      <td>0.652639</td>\n",
       "      <td>0.667422</td>\n",
       "      <td>0.697797</td>\n",
       "      <td>0.665265</td>\n",
       "      <td>0.671679</td>\n",
       "      <td>0.670960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dmoz-Science.csv</td>\n",
       "      <td>ollama</td>\n",
       "      <td>qwen2.5:7b</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>0.688759</td>\n",
       "      <td>0.694056</td>\n",
       "      <td>0.700061</td>\n",
       "      <td>0.680398</td>\n",
       "      <td>0.679367</td>\n",
       "      <td>0.688528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>0.807679</td>\n",
       "      <td>0.913998</td>\n",
       "      <td>0.822170</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>0.862566</td>\n",
       "      <td>0.845828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...</td>\n",
       "      <td>knn</td>\n",
       "      <td>base_prompt</td>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.917844</td>\n",
       "      <td>0.822991</td>\n",
       "      <td>0.887147</td>\n",
       "      <td>0.825480</td>\n",
       "      <td>0.869171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_summary_prompt</td>\n",
       "      <td>0.823295</td>\n",
       "      <td>0.897993</td>\n",
       "      <td>0.952120</td>\n",
       "      <td>0.907743</td>\n",
       "      <td>0.921861</td>\n",
       "      <td>0.900603</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised</td>\n",
       "      <td>knn</td>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.807781</td>\n",
       "      <td>0.794508</td>\n",
       "      <td>0.815568</td>\n",
       "      <td>0.798438</td>\n",
       "      <td>0.789926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>SyskillWebert.csv</td>\n",
       "      <td>llm2vec</td>\n",
       "      <td>McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised</td>\n",
       "      <td>knn</td>\n",
       "      <td>base_prompt</td>\n",
       "      <td>0.841728</td>\n",
       "      <td>0.899038</td>\n",
       "      <td>0.911935</td>\n",
       "      <td>0.892391</td>\n",
       "      <td>0.952610</td>\n",
       "      <td>0.899540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>374 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dataset_name model_type  \\\n",
       "0     Dmoz-Science.csv     ollama   \n",
       "1     Dmoz-Science.csv     ollama   \n",
       "2     Dmoz-Science.csv     ollama   \n",
       "3     Dmoz-Science.csv     ollama   \n",
       "4     Dmoz-Science.csv     ollama   \n",
       "..                 ...        ...   \n",
       "369  SyskillWebert.csv    llm2vec   \n",
       "370  SyskillWebert.csv    llm2vec   \n",
       "371  SyskillWebert.csv    llm2vec   \n",
       "372  SyskillWebert.csv    llm2vec   \n",
       "373  SyskillWebert.csv    llm2vec   \n",
       "\n",
       "                                            model_name classifier  \\\n",
       "0                                           mistral:7b        knn   \n",
       "1                                           mistral:7b        knn   \n",
       "2                                           mistral:7b        knn   \n",
       "3                                           qwen2.5:7b        knn   \n",
       "4                                           qwen2.5:7b        knn   \n",
       "..                                                 ...        ...   \n",
       "369  McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...        knn   \n",
       "370  McGill-NLP_LLM2Vec-Mistral-7B-Instruct-v2-mntp...        knn   \n",
       "371   McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised        knn   \n",
       "372   McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised        knn   \n",
       "373   McGill-NLP_LLM2Vec-Sheared-LLaMA-mntp-supervised        knn   \n",
       "\n",
       "                           prompt_name  split0_test_f1_score  \\\n",
       "0           instruction_summary_prompt              0.593222   \n",
       "1    instruction_classification_prompt              0.629638   \n",
       "2                          base_prompt              0.537706   \n",
       "3           instruction_summary_prompt              0.652639   \n",
       "4    instruction_classification_prompt              0.688759   \n",
       "..                                 ...                   ...   \n",
       "369  instruction_classification_prompt              0.807679   \n",
       "370                        base_prompt              0.892391   \n",
       "371         instruction_summary_prompt              0.823295   \n",
       "372  instruction_classification_prompt              0.733333   \n",
       "373                        base_prompt              0.841728   \n",
       "\n",
       "     split1_test_f1_score  split2_test_f1_score  split3_test_f1_score  \\\n",
       "0                0.592466              0.602268              0.561719   \n",
       "1                0.649192              0.665732              0.634082   \n",
       "2                0.551799              0.563238              0.549503   \n",
       "3                0.667422              0.697797              0.665265   \n",
       "4                0.694056              0.700061              0.680398   \n",
       "..                    ...                   ...                   ...   \n",
       "369              0.913998              0.822170              0.822727   \n",
       "370              0.917844              0.822991              0.887147   \n",
       "371              0.897993              0.952120              0.907743   \n",
       "372              0.807781              0.794508              0.815568   \n",
       "373              0.899038              0.911935              0.892391   \n",
       "\n",
       "     split4_test_f1_score  mean_test_f1_score  embedding_generation_time  \\\n",
       "0                0.578065            0.585548                        NaN   \n",
       "1                0.634035            0.642536                        NaN   \n",
       "2                0.546192            0.549688                        NaN   \n",
       "3                0.671679            0.670960                        NaN   \n",
       "4                0.679367            0.688528                        NaN   \n",
       "..                    ...                 ...                        ...   \n",
       "369              0.862566            0.845828                        NaN   \n",
       "370              0.825480            0.869171                        NaN   \n",
       "371              0.921861            0.900603                        NaN   \n",
       "372              0.798438            0.789926                        NaN   \n",
       "373              0.952610            0.899540                        NaN   \n",
       "\n",
       "    embedding_generation_size  \n",
       "0                        None  \n",
       "1                        None  \n",
       "2                        None  \n",
       "3                        None  \n",
       "4                        None  \n",
       "..                        ...  \n",
       "369                      None  \n",
       "370                      None  \n",
       "371                      None  \n",
       "372                      None  \n",
       "373                      None  \n",
       "\n",
       "[374 rows x 13 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_path = 'results' \n",
    "\n",
    "df = load_results_to_dataframe(base_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert</td>\n",
       "      <td>[0.7814881599520914, 0.7814233885535803, 0.807...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>llm2vec</td>\n",
       "      <td>[0.8063511747045715, 0.7997685567439344, 0.840...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ollama</td>\n",
       "      <td>[0.5932220682569391, 0.5924657799692853, 0.602...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                                                  0\n",
       "0       bert  [0.7814881599520914, 0.7814233885535803, 0.807...\n",
       "1    llm2vec  [0.8063511747045715, 0.7997685567439344, 0.840...\n",
       "2     ollama  [0.5932220682569391, 0.5924657799692853, 0.602..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Defina os splits que você quer combinar\n",
    "splits = ['split0_test_f1_score', \n",
    "          'split1_test_f1_score', \n",
    "          'split2_test_f1_score', \n",
    "          'split3_test_f1_score', \n",
    "          'split4_test_f1_score']\n",
    "\n",
    "# Agrupar pelo 'prompt_name' e combinar os splits em uma lista para cada 'prompt_name'\n",
    "df_combined = df.groupby('model_type')[splits].apply(lambda x: x.values.flatten().tolist()).reset_index()\n",
    "\n",
    "# Exibir o resultado\n",
    "df_combined  # A coluna 0 contém a lista dos splits combinados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = df_combined[df_combined['model_type'] == \"bert\"][0].tolist()[0]\n",
    "llm2vec = df_combined[df_combined['model_type'] == \"llm2vec\"][0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste de Shapiro-Wilk para BERT: Estatística = 0.9261211660374754, p-valor = 4.718960862983999e-09\n",
      "Teste de Shapiro-Wilk para LLM2Vec: Estatística = 0.9394682999067311, p-valor = 1.199433054295266e-19\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#Se o p-valor for maior que 0,05: Os dados não apresentam evidências suficientes para rejeitar a hipótese de normalidade, ou seja, os dados podem ser considerados normalmente distribuídos.\n",
    "#Se o p-valor for menor que 0,05: Os dados provavelmente não seguem uma distribuição normal, o que pode indicar a necessidade de ajustes ou o uso de testes não paramétricos.\n",
    "\n",
    "# Teste de Shapiro-Wilk para normalidade\n",
    "shapiro_bert_stat, shapiro_bert_p = stats.shapiro(bert)\n",
    "shapiro_llm2vec_stat, shapiro_llm2vec_p = stats.shapiro(llm2vec)\n",
    "\n",
    "# Imprimir os resultados do teste de Shapiro-Wilk\n",
    "print(f'Teste de Shapiro-Wilk para BERT: Estatística = {shapiro_bert_stat}, p-valor = {shapiro_bert_p}')\n",
    "print(f'Teste de Shapiro-Wilk para LLM2Vec: Estatística = {shapiro_llm2vec_stat}, p-valor = {shapiro_llm2vec_p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatística de Kruskal-Wallis: 1.8606317712580547\n",
      "Valor-p: 0.1725519025126044\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Executando o teste de Kruskal-Wallis\n",
    "stat, p_value = kruskal(bert, llm2vec)\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(f\"Estatística de Kruskal-Wallis: {stat}\")\n",
    "print(f\"Valor-p: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana BERT: 0.8711143109091124\n",
      "Mediana LLM2Vec: 0.8776299372374904\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "import numpy as np\n",
    "\n",
    "# Cálculo das medianas para BERT e LLM2Vec\n",
    "mediana_bert = np.median(bert)\n",
    "mediana_llm2vec = np.median(llm2vec)\n",
    "\n",
    "print(f'Mediana BERT: {mediana_bert}')\n",
    "print(f'Mediana LLM2Vec: {mediana_llm2vec}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_name</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_prompt</td>\n",
       "      <td>[0.5377064641913295, 0.5517986440058487, 0.563...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>instruction_classification_prompt</td>\n",
       "      <td>[0.6296381839440847, 0.6491923816459985, 0.665...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>instruction_summary_prompt</td>\n",
       "      <td>[0.5932220682569391, 0.5924657799692853, 0.602...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         prompt_name  \\\n",
       "0                        base_prompt   \n",
       "1  instruction_classification_prompt   \n",
       "2         instruction_summary_prompt   \n",
       "\n",
       "                                                   0  \n",
       "0  [0.5377064641913295, 0.5517986440058487, 0.563...  \n",
       "1  [0.6296381839440847, 0.6491923816459985, 0.665...  \n",
       "2  [0.5932220682569391, 0.5924657799692853, 0.602...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Defina os splits que você quer combinar\n",
    "splits = ['split0_test_f1_score', \n",
    "          'split1_test_f1_score', \n",
    "          'split2_test_f1_score', \n",
    "          'split3_test_f1_score', \n",
    "          'split4_test_f1_score']\n",
    "\n",
    "# Agrupar pelo 'prompt_name' e combinar os splits em uma lista para cada 'prompt_name'\n",
    "df_combined = df.groupby('prompt_name')[splits].apply(lambda x: x.values.flatten().tolist()).reset_index()\n",
    "\n",
    "# Exibir o resultado\n",
    "df_combined  # A coluna 0 contém a lista dos splits combinados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = df_combined[df_combined['prompt_name'] == \"base_prompt\"][0].tolist()[0]\n",
    "instruction_summary_prompt = df_combined[df_combined['prompt_name'] == \"instruction_summary_prompt\"][0].tolist()[0]\n",
    "instruction_classification_prompt = df_combined[df_combined['prompt_name'] == \"instruction_classification_prompt\"][0].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapiro-Wilk:\n",
      "base_prompt: ShapiroResult(statistic=np.float64(0.9651226999400369), pvalue=np.float64(3.827298012360926e-10))\n",
      "instruction_summary_prompt: ShapiroResult(statistic=np.float64(0.972072471875919), pvalue=np.float64(9.80213675867632e-09))\n",
      "instruction_classification_prompt: ShapiroResult(statistic=np.float64(0.9708462662678546), pvalue=np.float64(5.351582475352289e-09))\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "#Se o p-valor for maior que 0,05: Os dados não apresentam evidências suficientes para rejeitar a hipótese de normalidade, ou seja, os dados podem ser considerados normalmente distribuídos.\n",
    "#Se o p-valor for menor que 0,05: Os dados provavelmente não seguem uma distribuição normal, o que pode indicar a necessidade de ajustes ou o uso de testes não paramétricos.\n",
    "\n",
    "# Teste de Shapiro-Wilk\n",
    "shapiro_base = shapiro(base_prompt)\n",
    "shapiro_summary = shapiro(instruction_summary_prompt)\n",
    "shapiro_classification = shapiro(instruction_classification_prompt)\n",
    "\n",
    "print(\"Shapiro-Wilk:\")\n",
    "print(\"base_prompt:\", shapiro_base)\n",
    "print(\"instruction_summary_prompt:\", shapiro_summary)\n",
    "print(\"instruction_classification_prompt:\", shapiro_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatística de Kruskal-Wallis: 0.08170979181693862\n",
      "Valor-p: 0.9599684151869093\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Executando o teste de Kruskal-Wallis\n",
    "stat, p_value = kruskal(base_prompt, instruction_summary_prompt, instruction_classification_prompt)\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(f\"Estatística de Kruskal-Wallis: {stat}\")\n",
    "print(f\"Valor-p: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = df[df['model_type'] == 'bert']['embedding_generation_time']\n",
    "llm2vec = df[df['model_type'] == 'llm2vec']['embedding_generation_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teste de Shapiro-Wilk para BERT: Estatística = nan, p-valor = nan\n",
      "Teste de Shapiro-Wilk para LLM2Vec: Estatística = nan, p-valor = nan\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "#Se o p-valor for maior que 0,05: Os dados não apresentam evidências suficientes para rejeitar a hipótese de normalidade, ou seja, os dados podem ser considerados normalmente distribuídos.\n",
    "#Se o p-valor for menor que 0,05: Os dados provavelmente não seguem uma distribuição normal, o que pode indicar a necessidade de ajustes ou o uso de testes não paramétricos.\n",
    "\n",
    "# Teste de Shapiro-Wilk para normalidade\n",
    "shapiro_bert_stat, shapiro_bert_p = stats.shapiro(bert)\n",
    "shapiro_llm2vec_stat, shapiro_llm2vec_p = stats.shapiro(llm2vec)\n",
    "\n",
    "# Imprimir os resultados do teste de Shapiro-Wilk\n",
    "print(f'Teste de Shapiro-Wilk para BERT: Estatística = {shapiro_bert_stat}, p-valor = {shapiro_bert_p}')\n",
    "print(f'Teste de Shapiro-Wilk para LLM2Vec: Estatística = {shapiro_llm2vec_stat}, p-valor = {shapiro_llm2vec_p}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estatística de Kruskal-Wallis: nan\n",
      "Valor-p: nan\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import kruskal\n",
    "\n",
    "# Executando o teste de Kruskal-Wallis\n",
    "stat, p_value = kruskal(bert, llm2vec)\n",
    "\n",
    "# Exibindo o resultado\n",
    "print(f\"Estatística de Kruskal-Wallis: {stat}\")\n",
    "print(f\"Valor-p: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mediana BERT: nan\n",
      "Mediana LLM2Vec: nan\n",
      "O modelo LLM2Vec tem os menores valores de tempo de geração de embeddings.\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import rankdata\n",
    "import numpy as np\n",
    "\n",
    "# Cálculo das medianas para BERT e LLM2Vec\n",
    "mediana_bert = np.median(bert)\n",
    "mediana_llm2vec = np.median(llm2vec)\n",
    "\n",
    "print(f'Mediana BERT: {mediana_bert}')\n",
    "print(f'Mediana LLM2Vec: {mediana_llm2vec}')\n",
    "\n",
    "# Comparando as medianas\n",
    "if mediana_bert < mediana_llm2vec:\n",
    "    print(\"O modelo BERT tem os menores valores de tempo de geração de embeddings.\")\n",
    "else:\n",
    "    print(\"O modelo LLM2Vec tem os menores valores de tempo de geração de embeddings.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
